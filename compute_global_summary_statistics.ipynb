{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - IMPORTS ---\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - FUNCTIONS ---\n",
    "def compute_summary_stats_for_csv_file(\n",
    "    csv_f:str,\n",
    "    coeff_type: str,\n",
    "    filter_columns: list\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute summary statistics for the given CSV file\n",
    "    \"\"\"\n",
    "    df_table = pd.read_csv(csv_f)\n",
    "    columns_oI = df_table.columns[2:-2]  # Select Only columns with numerical values\n",
    "    \n",
    "    if filter_columns != []:\n",
    "        columns_oI = filter_columns\n",
    "\n",
    "    # Filter the table\n",
    "    df_table_corr = df_table[df_table[\"Coeff\"] == f\"{coeff_type}_corr_coeffs\"]\n",
    "    df_table_p = df_table[df_table[\"Coeff\"] == f\"{coeff_type}_p_values\"]\n",
    "    \n",
    "    df_table_corr_f = pd.DataFrame(df_table_corr,\n",
    "                                   columns = columns_oI) \n",
    "\n",
    "    # Check which coefficient have a p value lover than threshold (statistically significant)\n",
    "    # TODO, use as filter: mask = (df_table_p_f < p_threhsold)  \n",
    "    df_table_p_f = pd.DataFrame(df_table_p,\n",
    "                                columns = columns_oI) \n",
    "    valid_df_table_corr = df_table_corr_f\n",
    "\n",
    "    summary_statistics = {'mean': valid_df_table_corr.mean(),\n",
    "                          'std': valid_df_table_corr.std(),\n",
    "                          'min': valid_df_table_corr.min(),\n",
    "                          '25% quantile': valid_df_table_corr.quantile(0.25),\n",
    "                          '50% quantile': valid_df_table_corr.quantile(0.50),\n",
    "                          '75% quantile': valid_df_table_corr.quantile(0.75),\n",
    "                          'max': valid_df_table_corr.max(),\n",
    "                          }\n",
    "\n",
    "    return pd.DataFrame(summary_statistics).T\n",
    "\n",
    "def filter_csv_files(sim_or_not, op_type, coeff_type, all_csv_files):\n",
    "    check = lambda file_name, options: any(o in file_name for o in options)\n",
    "    if sim_or_not != []:\n",
    "        all_csv_files = [f for f in all_csv_files if check(f, sim_or_not)]\n",
    "    if op_type != []:\n",
    "        all_csv_files = [f for f in all_csv_files if check(f, op_type)]\n",
    "    if coeff_type != []:\n",
    "        all_csv_files = [f for f in all_csv_files if check(f, coeff_type)]\n",
    "    return all_csv_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user_id/WORK_Station/VOS/UVOS/iVOTS_Benchmark\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "\n",
       "### ../intermediate/iVOTS_benchmark/GT_mask/iou_entropy_analysis_HUB/QDMN_S/d17-val/summary_stats/mask_H_5/noxsim_sum_base.csv \n",
       "|              |   Total_H_base |   TR_H_base |   FR_H_base |   Total_H_masked_pd |   TR_H_masked_pd |   FR_H_masked_pd |\n",
       "|:-------------|---------------:|------------:|------------:|--------------------:|-----------------:|-----------------:|\n",
       "| mean         |     -0.0648034 |   0.0149762 |  -0.302456  |          0.00182079 |        0.108711  |        -0.235366 |\n",
       "| std          |      0.543928  |   0.516579  |   0.512234  |          0.52237    |        0.498856  |         0.523951 |\n",
       "| min          |     -0.800397  |  -0.754247  |  -0.96898   |         -0.815947   |       -0.678367  |        -0.96898  |\n",
       "| 25% quantile |     -0.52414   |  -0.394658  |  -0.714729  |         -0.400606   |       -0.271447  |        -0.689714 |\n",
       "| 50% quantile |     -0.217955  |  -0.126887  |  -0.412478  |         -0.0890466  |        0.0548714 |        -0.345646 |\n",
       "| 75% quantile |      0.529172  |   0.5718    |   0.0690913 |          0.412574   |        0.543793  |         0.161797 |\n",
       "| max          |      0.902277  |   0.920914  |   0.785589  |          0.928213   |        0.946422  |         0.882376 | \n",
       "\n",
       "### ../intermediate/iVOTS_benchmark/GT_mask/iou_entropy_analysis_HUB/QDMN_S/d17-val/summary_stats/mask_H_5/noxsim_sum_pd.csv \n",
       "|              |   Total_H_base |   TR_H_base |   FR_H_base |   Total_H_masked_pd |   TR_H_masked_pd |   FR_H_masked_pd |\n",
       "|:-------------|---------------:|------------:|------------:|--------------------:|-----------------:|-----------------:|\n",
       "| mean         |      -0.547974 |   -0.462147 |   -0.865005 |           -0.580908 |        -0.435488 |        -0.811721 |\n",
       "| std          |       0.430551 |    0.451044 |    0.199808 |            0.407692 |         0.458927 |         0.276471 |\n",
       "| min          |      -0.95587  |   -0.926721 |   -0.990556 |           -0.929555 |        -0.891257 |        -0.982957 |\n",
       "| 25% quantile |      -0.836908 |   -0.752386 |   -0.958255 |           -0.857635 |        -0.753252 |        -0.954093 |\n",
       "| 50% quantile |      -0.661139 |   -0.593231 |   -0.937371 |           -0.7207   |        -0.609236 |        -0.927533 |\n",
       "| 75% quantile |      -0.523478 |   -0.375842 |   -0.840625 |           -0.544418 |        -0.292426 |        -0.807126 |\n",
       "| max          |       0.604453 |    0.725686 |    0.324576 |            0.619985 |         0.805044 |         0.477142 | \n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Results adapted to be pasted in a markdown file\n",
      "\n",
      "---\n",
      "\n",
      "### ../intermediate/iVOTS_benchmark/GT_mask/iou_entropy_analysis_HUB/QDMN_S/d17-val/summary_stats/mask_H_5/noxsim_sum_base.csv \n",
      "|              |   Total_H_base |   TR_H_base |   FR_H_base |   Total_H_masked_pd |   TR_H_masked_pd |   FR_H_masked_pd |\n",
      "|:-------------|---------------:|------------:|------------:|--------------------:|-----------------:|-----------------:|\n",
      "| mean         |     -0.0648034 |   0.0149762 |  -0.302456  |          0.00182079 |        0.108711  |        -0.235366 |\n",
      "| std          |      0.543928  |   0.516579  |   0.512234  |          0.52237    |        0.498856  |         0.523951 |\n",
      "| min          |     -0.800397  |  -0.754247  |  -0.96898   |         -0.815947   |       -0.678367  |        -0.96898  |\n",
      "| 25% quantile |     -0.52414   |  -0.394658  |  -0.714729  |         -0.400606   |       -0.271447  |        -0.689714 |\n",
      "| 50% quantile |     -0.217955  |  -0.126887  |  -0.412478  |         -0.0890466  |        0.0548714 |        -0.345646 |\n",
      "| 75% quantile |      0.529172  |   0.5718    |   0.0690913 |          0.412574   |        0.543793  |         0.161797 |\n",
      "| max          |      0.902277  |   0.920914  |   0.785589  |          0.928213   |        0.946422  |         0.882376 | \n",
      "\n",
      "### ../intermediate/iVOTS_benchmark/GT_mask/iou_entropy_analysis_HUB/QDMN_S/d17-val/summary_stats/mask_H_5/noxsim_sum_pd.csv \n",
      "|              |   Total_H_base |   TR_H_base |   FR_H_base |   Total_H_masked_pd |   TR_H_masked_pd |   FR_H_masked_pd |\n",
      "|:-------------|---------------:|------------:|------------:|--------------------:|-----------------:|-----------------:|\n",
      "| mean         |      -0.547974 |   -0.462147 |   -0.865005 |           -0.580908 |        -0.435488 |        -0.811721 |\n",
      "| std          |       0.430551 |    0.451044 |    0.199808 |            0.407692 |         0.458927 |         0.276471 |\n",
      "| min          |      -0.95587  |   -0.926721 |   -0.990556 |           -0.929555 |        -0.891257 |        -0.982957 |\n",
      "| 25% quantile |      -0.836908 |   -0.752386 |   -0.958255 |           -0.857635 |        -0.753252 |        -0.954093 |\n",
      "| 50% quantile |      -0.661139 |   -0.593231 |   -0.937371 |           -0.7207   |        -0.609236 |        -0.927533 |\n",
      "| 75% quantile |      -0.523478 |   -0.375842 |   -0.840625 |           -0.544418 |        -0.292426 |        -0.807126 |\n",
      "| max          |       0.604453 |    0.725686 |    0.324576 |            0.619985 |         0.805044 |         0.477142 | \n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# - PARAMETERS ---\n",
    "\n",
    "# Import from parent folder\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "print(Path.cwd())\n",
    "#print(str(Path.cwd()).replace(\"notebooks\", \"configuration\"))\n",
    "#print(\"/home/user_id/WORK_Station/VOS/UVOS/iVOTS_Benchmark/configuration\")\n",
    "#sys.path.append(str(Path.cwd()).replace(\"notebooks\", \"configuration\"))\n",
    "\n",
    "from configuration.configuration_manager import ConfigManager\n",
    "\n",
    "dataset_name = \"lvos-val\"  #\"d17-val\", \"lvos-val\"\n",
    "method_name = \"Ensemble_v3\"#\"UXMem_s012_base\" #\"Ensemble_v3\" #'UXMem_s012_base' #'XMem_Ensemble_3_v2' #\"XMem_Ensemble_2\" #'QDMN'\n",
    "\n",
    "dataset_name = \"d17-val\"  #\"d17-val\", \"lvos-val\"\n",
    "method_name = \"QDMN_S\" #\"UXMem_s012_base\" #\"Ensemble_v3\" #'UXMem_s012_base' #'XMem_Ensemble_3_v2' #\"XMem_Ensemble_2\" #'QDMN'\n",
    "\n",
    "#\"UXMem_s012_base\" #\"XMem\"\n",
    "sim_or_not = ['noxsim_']  # 'yexsim_', 'noxsim_'\n",
    "op_type = ['_sum_']  # '_mean_', '_median_', '_sum_'\n",
    "coeff_type = \"spearman\"  # 'spearman', 'pearson'\n",
    "temperature = 1.0\n",
    "mask_H = 5\n",
    "\n",
    "def gen_location_for_the_csv_file(_save_analysis_loc, mask_H=None):\n",
    "    _save_analysis_loc = os.path.join(_save_analysis_loc, \"raw_stats_HUB\")\n",
    "    if mask_H is not None:\n",
    "        _save_analysis_loc = os.path.join(_save_analysis_loc, \n",
    "                                          f\"mask_H_{mask_H}\")\n",
    "    else:\n",
    "        _save_analysis_loc = os.path.join(_save_analysis_loc, \"no_mask_H\")\n",
    "\n",
    "    return _save_analysis_loc\n",
    "\n",
    "\n",
    "# Configuration/ Available methods and datasets\n",
    "config = ConfigManager()\n",
    "avail_datasets = config.get_all_available_datasets()\n",
    "avail_methods = config.get_all_available_methods()\n",
    "config['dataset_name'] = dataset_name\n",
    "config['method_name'] = method_name\n",
    "config_generator = config.get_my_configuration()\n",
    "\n",
    "# TODO: adapt this !!\n",
    "image_directory, gt_mask_directory = next(config_generator)\n",
    "pred_mask_directory, logits_directory, softmax_directory = \\\n",
    "    next(config_generator)\n",
    "entropy_directory, confusion_directory = next(config_generator)\n",
    "preprocessing_directory = next(config_generator)\n",
    "save_analysis_loc = config.get_iou_entropy_analysis_path()\n",
    "loc_to_save_csv_results = gen_location_for_the_csv_file(save_analysis_loc, mask_H)\n",
    "\n",
    "if temperature != 1.0:\n",
    "    entropy_directory = entropy_directory + f'_Temp_{temperature}'\n",
    "    loc_to_save_csv_results += f'_Temp_{temperature}'\n",
    "\n",
    "\n",
    "raw_stats_path = loc_to_save_csv_results\n",
    "root, end = raw_stats_path.split('/raw_stats_HUB/')\n",
    "final_stats_path = os.path.join(root, \"summary_stats\", end)\n",
    "stats_location = os.path.join(final_stats_path)\n",
    "directories = os.listdir(stats_location)\n",
    "\n",
    "if method_name == \"QDMN\":\n",
    "    focus_on_columns = [\"QAM_score_fdx\", \"QAM_score_fdx_obx\"]\n",
    "\n",
    "else:\n",
    "    focus_on_columns = [\"Total_H_base\", \"TR_H_base\", \"FR_H_base\",\n",
    "                        # \"Total_H_masked_gt\", \"TR_H_masked_gt\", \"FR_H_masked_gt\",\n",
    "                        \"Total_H_masked_pd\", \"TR_H_masked_pd\", \"FR_H_masked_pd\"]\n",
    "\n",
    "# - MAIN ---\n",
    "summary_markdown = \"\\n---\\n\" \n",
    "all_csv_files = filter_csv_files(sim_or_not, op_type, coeff_type, directories)\n",
    "\n",
    "type_table = \"Markdown\"\n",
    "\n",
    "for csv_f in all_csv_files:\n",
    "    csv_f = os.path.join(stats_location, csv_f)\n",
    "    summary_table = compute_summary_stats_for_csv_file(csv_f, coeff_type, focus_on_columns)\n",
    "    if \"Markdown\" == type_table:\n",
    "        markdown_str = summary_table.to_markdown()\n",
    "    elif \"Latex\" == type_table:\n",
    "        markdown_str = summary_table.to_latex()\n",
    "    else:\n",
    "        markdown_str = summary_table.to_markdown()\n",
    "    summary_markdown += f\"\\n### {csv_f} \\n{markdown_str} \\n\"\n",
    "\n",
    "summary_markdown = summary_markdown + \"\\n---\"\n",
    "display(Markdown(summary_markdown))\n",
    "\n",
    "print(\"\\n\\n Results adapted to be pasted in a markdown file\")\n",
    "print(summary_markdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
